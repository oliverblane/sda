{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "from numpy import mean\n",
    "from scipy import stats\n",
    "from math import factorial\n",
    "\n",
    "def variance(x):\n",
    "    mean = np.mean(x)\n",
    "    total = 0\n",
    "    for element in x:\n",
    "        total += (element - mean)**2\n",
    "    return total/(len(x)-1)\n",
    "\n",
    "def std(x):\n",
    "    return np.sqrt(variance(x))\n",
    "\n",
    "def skew(x):\n",
    "    var = variance(x)\n",
    "    mean = np.mean(x)\n",
    "    total = 0\n",
    "    for element in x:\n",
    "        total += (element - mean)**3\n",
    "    return total / (len(x) * (var**(3/2)))\n",
    "\n",
    "def covariance(x, y):\n",
    "    mean_x, mean_y = np.mean(x), np.mean(y)\n",
    "    total = 0\n",
    "    for i in range(len(x)):\n",
    "        total += (x[i] - mean_x)*(y[i] - mean_y)\n",
    "    \n",
    "    return total/(len(x)-1)\n",
    "\n",
    "def spearman(x, y):\n",
    "    \"\"\"Calculates Spearman Rank Coefficient for two arrays of data,\n",
    "    x and y.\"\"\"\n",
    "    sorted_x_idx = stats.rankdata(x)\n",
    "    sorted_y_idx = stats.rankdata(y)\n",
    "    total = 0\n",
    "    N = len(x)\n",
    "    for i in range(N):\n",
    "        total += (sorted_x_idx[i] - sorted_y_idx[i])**2\n",
    "        \n",
    "    return (1 - (6*total) / (N * (N**2 - 1)))\n",
    "\n",
    "def binomial(r, p, n):\n",
    "    frac = (factorial(n) / (factorial(r)*factorial(n-r)))\n",
    "    return p**r * (1 - p)**(n - r) * frac\n",
    "\n",
    "def poisson(r, lam):\n",
    "    return (lam**r * np.exp(-lam)) / factorial(r)\n",
    "\n",
    "def poisson_cumulative(r_range, lam, limits=True):\n",
    "    \"\"\"Calculates the cumulative probability for a Poisson distribution.\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    PARAMETERS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    r_range: array-like\n",
    "              if limits=True, then this array should contain the upper and lower limit\n",
    "              of the r values that are desired to be calculated. The r value is the number\n",
    "              of outcomes.\n",
    "              Otherwise, this should contain the array of r_values that are desired to be\n",
    "              summed.\n",
    "    \n",
    "    lam: integer\n",
    "         the expected number of outcomes.\n",
    "    \n",
    "    limits: boolean\n",
    "            default is True.\n",
    "            True - r_range will be treated as an array containing the lower and upper limits\n",
    "            respectively of the range of r values to be calculated.\n",
    "            False - r_range will be treated as an array containing the r values to be\n",
    "            calculated.\n",
    "            \n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    if limits == True:\n",
    "        if len(r_range) != 2:\n",
    "            print(\"When limits=True, r_range should contain simply a lower an upper limit\")\n",
    "            return None\n",
    "            \n",
    "        a = r_range[0]\n",
    "        b = r_range[1]\n",
    "        r_values = np.linspace(a, b, 1 + (b - a))\n",
    "\n",
    "        for r in r_values:\n",
    "            total += poisson(r, lam)\n",
    "            \n",
    "    else:\n",
    "        for r in r_range:\n",
    "            total += poisson(r, lam)\n",
    "        \n",
    "    return total\n",
    "\n",
    "def gaussian(x, mu, sigma):\n",
    "    return (1 / (sigma*np.sqrt(2*np.pi))) * np.exp(-((x - mu)**2)/(2*sigma**2))\n",
    "\n",
    "def Gamma(n):\n",
    "    return factorial(n-1)\n",
    "\n",
    "def chi_squared(chisq, nu):\n",
    "    return (2**(-nu/2) * chisq**(nu/2 - 1) * np.exp(-chisq/2)) / Gamma(nu/2)\n",
    "\n",
    "def uniform(x, N):\n",
    "    return 1/N\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = [.5, .9, 1.2, 1.5, 1.8, 2, 3.4, 4.1, 5, 5.1, 7.5, 8.5]\n",
    "k = [.7, .8, 1.1, 1.2, 1.5, 1.8, 1.9, 2, 2.5, 2.6, 2.9, 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95135429, -0.30809905],\n",
       "       [ 0.30809905,  0.95135429]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = np.array([[variance(omega), covariance(omega, k)],\n",
    "             [covariance(omega, k), variance(k)]])\n",
    "\n",
    "eigenvalues, eigenvectors = eig(V)\n",
    "eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n",
      "3.0\n",
      "1.7320508075688772\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "omega = [1, 2.5, 3, 4, 4.5, 6]\n",
    "print(np.mean(omega))\n",
    "print(variance(omega))\n",
    "print(std(omega))\n",
    "print(skew(omega))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7428571428571427\n",
      "0.7428571428571429\n",
      "0.8618916073713346\n",
      "0.026638133469581587\n"
     ]
    }
   ],
   "source": [
    "omega = [.5, 1, 1.5, 1.6, 3, 2.1, 2.5]\n",
    "print(np.mean(omega))\n",
    "print(variance(omega))\n",
    "print(std(omega))\n",
    "print(skew(omega))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017000000000000008"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [.1, .22, .25, .5, .55, .7, .8, .9, 1, 1.11, 1.12]\n",
    "y = [1, 1.1, 1.1, 1.2, 1.3, 1.4, 1.4, 1.3, 1.6, 1.5, 1.4]\n",
    "z = [.1, -.2, .3, .4, .1, -.4, .1, -.1, .6, .7, -.3]\n",
    "\n",
    "covariance(y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25806092613071363"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".017 / (std(y) * std(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8332164480906891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [0, .2, .3, .4, .5, .7, .8, .9, 1, .9, 1.1]\n",
    "y = [.9, 1.1, 1.2, 1.2, 1.3, 1.4, 1.5, 1.3, 1.6, 1.5, 1.3]\n",
    "z = [-.1, -.2, .1, .2, .1, 0, .2, .1, .5, .6, .3]\n",
    "\n",
    "covariance(x, y) / (std(x) * std(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5857142857142856"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [.5, .7, .8, .9, 1.1, 1.3]\n",
    "y = [.9, .8, 1.1, 1.2, 1.2, 1]\n",
    "\n",
    "spearman(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.027272727272727337"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [.1, .3, .2, 0, .4, .5, .1, .2, .6, .5]\n",
    "y = [.5, .7, .2, .3, .8, .1, .9, 0, .4, .6]\n",
    "\n",
    "spearman(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23040000000000005"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binomial(3, .4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049787068367863944"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07326255555493671, 0.15629345185053165)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson(1, 4), poisson(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46875000000000006"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson(1, 4) / poisson(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6065306597126334"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian(1, 0, 1) / gaussian(0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared(chisq, nu):\n",
    "    return (2**(-nu/2) * chisq**(nu/2 - 1) * np.exp(-chisq/2)) / Gamma(nu/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1026062482798735"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007897534631674915"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030656620097620196"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared(2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018315638888734182"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2.sf(8, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainties\n",
    "\n",
    "## Weighted Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_av_single(x, errors):\n",
    "    \"\"\"Calculates the weighted average of a set of measurements for a \n",
    "    single observation.\n",
    "    \n",
    "    Returns the weighted average and the error.\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    PARAMETERS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    x: list containing the measurements\n",
    "    errors: list containing the errors.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_top = 0\n",
    "    total_bottom = 0\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        var = errors[i]**2\n",
    "        total_top += x[i] / var\n",
    "        total_bottom += 1/var\n",
    "        \n",
    "    mean_x = total_top/total_bottom\n",
    "    sigma_x = 1/np.sqrt(total_bottom)\n",
    "        \n",
    "    return mean_x, sigma_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6628564627744128, 0.021870089601599807)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_av_single([.655, .59, .789], [.024, .08, .071])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5, 0.35355339059327373)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_av_single([1, 2], [.5, .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance([2, 1.5], [0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.81907285, -0.73774834]),\n",
       " array([[0.02930861, 0.01299338],\n",
       "        [0.01299338, 0.06615894]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weighted_av_set(measurements, errors, correlation, precision=None):\n",
    "    \"\"\"Calculates the weighted average of a set of measurements for a \n",
    "    set of observables.\n",
    "    \n",
    "    Returns the weighted average and the error.\n",
    "    \n",
    "    CURRENTLY ONLY BUILT FOR 2D.\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    PARAMETERS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    measurements: list of lists containing the measurements for each\n",
    "                    experiment\n",
    "    errors: list of lists containing the errors for each experiment\n",
    "    correlation: list of lists containing the correlations for each \n",
    "                    experiment\n",
    "    \"\"\"\n",
    "    V_list = []\n",
    "    x_list = []\n",
    "    size = len(measurements)\n",
    "    \n",
    "    for i in range(size):\n",
    "        corr_mat = np.ones((size, size))\n",
    "        cov_mat = np.ones((size, size))*correlation[i][0]*errors[i][0]*errors[i][1]\n",
    "        for j in range(len(errors[i])):\n",
    "            cov_mat[j, j] = errors[i][j]**2\n",
    "            \n",
    "            #corr_mat[j, -j-1] = correlation[i][0]\n",
    "\n",
    "        inv_cov = np.linalg.inv(cov_mat)\n",
    "        \n",
    "        V_list.append(inv_cov)\n",
    "        x_list.append(inv_cov @ measurements[i])\n",
    "            \n",
    "    V = np.linalg.inv(sum(V_list))\n",
    "    x = V @ (sum(x_list))\n",
    "    \n",
    "    if precision == None:\n",
    "        return x, V\n",
    "    \n",
    "    else:\n",
    "        return np.round(x, precision), np.round(V, precision)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "# format: [expt1], [expt2], ...\n",
    "measurements = [[2, 0], [1.5, -1]]\n",
    "errors = [[.2, .5], [.5, .3]]\n",
    "correlation = [[.5], [.1]]\n",
    "\n",
    "weighted_av_set(measurements, errors, correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.58506224, 0.10995851]),\n",
       " array([[0.12033195, 0.00311203],\n",
       "        [0.00311203, 0.00792531]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format: [expt1], [expt2], ...\n",
    "measurements = [[2, 0], [1.5, .5]]\n",
    "errors = [[.5, .1], [.5, .2]]\n",
    "correlation = [[0], [.3]]\n",
    "\n",
    "weighted_av_set(measurements, errors, correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.7071067811865475)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [3, 2]\n",
    "B = [0, 1]\n",
    "C = [0, 1]\n",
    "weighted_av_single(B, [1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_ratio(data, hypotheses=[gaussian, uniform], params=[[0, 1], [10]]):\n",
    "    \"\"\"Calculates the product of all ratios between the two hypotheses\n",
    "    for a given set of data.\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    PARAMETERS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    data: the data to which the two hypotheses apply\n",
    "    hypotheses: the two distributions that we wish to compare for the data\n",
    "    params: the parameters for the given hypotheses\"\"\"\n",
    "    h0, h1 = hypotheses\n",
    "    PI = 1\n",
    "    for w in data:\n",
    "        PI *= h0(w, *params[0]) / h1(w, *params[1])\n",
    "    \n",
    "    return PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140289.8050224156"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega = [-1.0, -0.9, -0.7, -0.1, 0.0, 0.1, 0.2, 0.5, 0.6, 1.0]\n",
    "hypothesis_ratio(omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5611082650219095e-13"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega = {-4, -3, -2, -1, 0, 1, 2, 3, 4, 5}\n",
    "hypothesis_ratio(omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019061171028699187"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega = {0, .1, .15, .2, .21}\n",
    "hypothesis_ratio(omega, hypotheses=[uniform, gaussian], params=[[len(omega)], (.15, .9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.05 / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_theorem(p_c_a, p_c_b, p_a):\n",
    "    \"\"\"\n",
    "    Calculates Bayes' Theorem for a scenario with two possible main\n",
    "    outcomes.\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    PARAMETERS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    p_c_a: probability of event c given a is true\n",
    "    p_c_b: probability of event c given b is true\n",
    "    p_a: probability of event a being true\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    EXAMPLE\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    Consider a test that correctly predicts infection at a rate of 98%,\n",
    "    and incorrectly predicts infection at a rate of 0.05%. The percentage\n",
    "    of infected individuals in the population is 0.01%. The probability\n",
    "    that someone is infected given a positive test result can be found\n",
    "    using the following logic:\n",
    "    \n",
    "    - Event a is infection\n",
    "    - Event b is health\n",
    "    - Event c is a positive test\n",
    "    \n",
    "    bayes_theorem(0.98, 0.0005, 0.0001)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    p_b = 1 - p_a\n",
    "    p_c = p_c_a*p_a + p_c_b*p_b\n",
    "    \n",
    "    p_a_c = (p_c_a*p_a) / (p_c)\n",
    "    \n",
    "    return p_a_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1638933021155615"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_theorem(.98, .0005, .0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9091653027823241"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_theorem(.9999, .0001, .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999909991809255"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_theorem(.9999, 1/1_000_000, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.525890604554078"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega = [0, 1, 2, 4, 6]\n",
    "hypothesis_ratio(omega, [poisson, poisson], [[3], [4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8367103680728915"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega = [1, 2, 3, 5, 7]\n",
    "hypothesis_ratio(omega, [poisson, poisson], [[3], [4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23838255092637145"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega = [1, 2, 3, 4, 5]\n",
    "hypothesis_ratio(omega, [binomial, gaussian], [[.4, len(omega)], [3, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002262536761766798"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - poisson_cumulative([0, 14], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chisq_scan(measurements, errors, scan_range, increment=.1,\n",
    "              same_errors=False):\n",
    "    \"\"\"Estimates the parameters that minimize chi-squared using\n",
    "    scanning across a desired range.\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    PARAMETERS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    measurements: array\n",
    "                  list of measurements\n",
    "    \n",
    "    errors: array\n",
    "            list of errors. If all errors are equal, can simply use\n",
    "            a list of length 1 with the error, and set same_errors=True.\n",
    "            \n",
    "    scan_range: tuple\n",
    "                the range across which you want parameters to be searched.\n",
    "                \n",
    "    increment: float \n",
    "               the increments between consecutive searches.\n",
    "               \n",
    "    same_errors: boolean\n",
    "                 default is False. Set to true if all errors are equal,\n",
    "                 and allow errors to only contain one element with the\n",
    "                 error.\n",
    "                 \n",
    "    -+-+-+-+-+-\n",
    "    RETURNS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    x_min: the bin that corresponds to the lowest total chi-squared value\n",
    "    \n",
    "    sigma: the error associated to x_min\n",
    "    \n",
    "    chi_totals: the chi-squared total values for each bin\n",
    "                 \n",
    "    \"\"\"\n",
    "    a, b = scan_range\n",
    "    x_values = np.arange(a, b+increment, increment)\n",
    "    N = len(measurements)\n",
    "    \n",
    "    chi_totals = []\n",
    "    \n",
    "    if same_errors == True:\n",
    "        errors = [errors[0] for i in range(N)]\n",
    "    \n",
    "    for x in x_values:\n",
    "        chi_values = []\n",
    "        for i in range(len(measurements)):\n",
    "            chi = ((measurements[i] - x) / errors[i])**2\n",
    "            chi_values.append(chi)\n",
    "        chi_totals.append(sum(chi_values))\n",
    "        \n",
    "    idx_min = np.argmin(chi_totals)\n",
    "    delta_chi = 0\n",
    "    idx_low = idx_min\n",
    "    while delta_chi < 1:\n",
    "        idx_low -= 1\n",
    "        delta_chi = chi_totals[idx_low] - chi_totals[idx_min]\n",
    "\n",
    "    delta_chi = 0\n",
    "    idx_high = idx_min\n",
    "    while delta_chi < 1:\n",
    "        idx_high += 1\n",
    "        delta_chi = chi_totals[idx_high] - chi_totals[idx_min]\n",
    "    \n",
    "    x_min = x_values[idx_min]\n",
    "    chi_errors = []\n",
    "    for i in range(-1, 2, 2):\n",
    "        delta_chi = 0\n",
    "        idx = idx_min\n",
    "        while delta_chi < 1:\n",
    "            idx += i\n",
    "            delta_chi = chi_totals[idx] - chi_totals[idx_min]\n",
    "        chi_errors.append(abs(x_min - x_values[idx]))\n",
    "    \n",
    "    sigma = np.mean(chi_errors)\n",
    "    return x_min, sigma, chi_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5000000000000004"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements = [1.2, 1.8]\n",
    "chisq_scan(measurements, [.3], (1, 2), same_errors=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6900000000000001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements = [.662, .625, .897, .614, .925, .694, .601]\n",
    "errors = [.039, .091, .100, .160, .160, .061, .239]\n",
    "chisq_scan(measurements, errors, (.6, 1), increment=.01)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6901364773080294, 0.0283683980386136)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_av_single(measurements, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2500000000000002"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements_7 = [1.3, 1.1]\n",
    "errors = [.1, .2]\n",
    "chisq_scan(measurements_7, errors, scan_range=(1.1, 1.4),increment=.05)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.26, 0.0894427190999916)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_av_single(measurements_7, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_least_squares_2d(x, y, sig):\n",
    "    \"\"\"\n",
    "    Estimates the parameters a and b for a 2d dataset for a model following\n",
    "    y = ax + b.\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    PARAMETERS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    x: array-like\n",
    "        contains x values\n",
    "        \n",
    "    y: array-like\n",
    "        contains y values\n",
    "        \n",
    "    sig: float\n",
    "         error associated with the values\n",
    "    \"\"\"\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    x2_mean = np.mean([i**2 for i in x])\n",
    "    xy_mean = np.mean([i*j for i, j in zip(x, y)])\n",
    "    \n",
    "    N = len(x)\n",
    "    \n",
    "    def a_func(xy_mean, x_mean, y_mean, x2_mean):\n",
    "        return (xy_mean - x_mean*y_mean)/(x2_mean - x_mean**2)\n",
    "    \n",
    "    def b_func(x_mean, y_mean, a):\n",
    "        return y_mean - a*x_mean\n",
    "\n",
    "    def sig_a_func(sig, N, x_mean, x2_mean):\n",
    "        return np.sqrt((sig**2)/(N*(x2_mean - x_mean**2)))\n",
    "    \n",
    "    def sig_b_func(sig, N, x_mean, x2_mean):\n",
    "        return np.sqrt((sig**2 * x2_mean)/(N*(x2_mean - x_mean**2)))\n",
    "    \n",
    "    a = a_func(xy_mean, x_mean, y_mean, x2_mean)\n",
    "    b = b_func(x_mean, y_mean, a)\n",
    "    sig_a = sig_a_func(sig, N, x_mean, x2_mean)\n",
    "    sig_b = sig_b_func(sig, N, x_mean, x2_mean)\n",
    "    \n",
    "    return a, b, sig_a, sig_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9753613214039927,\n",
       " -0.0472677219545794,\n",
       " 0.028738084397507524,\n",
       " 0.09065791491167298)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1.1, 1.5, 2, 3.1, 4.2, 5]\n",
    "y = [2, 2.9, 4.2, 6, 8, 10]\n",
    "lin_least_squares_2d(x, y, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.66,\n",
       " 0.025000000000000022,\n",
       " [12.353455140073633,\n",
       "  9.934205142828816,\n",
       "  7.933102035530877,\n",
       "  6.3501458181798185,\n",
       "  5.185336490775643,\n",
       "  4.438674053318347,\n",
       "  4.110158505807933,\n",
       "  4.199789848244398,\n",
       "  4.707568080627745,\n",
       "  5.633493202957973,\n",
       "  6.977565215235081])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements = [.655, .59, .789]\n",
    "errors = [.024, .08, .071]\n",
    "chisq_scan(measurements, errors, (.6, .7), increment=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<x> = 1.25 Â± 0.10\n"
     ]
    }
   ],
   "source": [
    "measurements = [1.3, 1.1]\n",
    "errors = [.1, .2]\n",
    "x_mean, sig, chisq = chisq_scan(measurements, errors, (1.1, 1.4),\n",
    "                                increment=.05)\n",
    "print(u\"<x> = {:.2f} \\u00B1 {:.2f}\".format(x_mean, sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_disc(mu_a, mu_b, V_a, V_b):\n",
    "    \"\"\"Calculates the fisher discriminant coefficients for a dataset\n",
    "    in which we know which elements are of class A and which are of class\n",
    "    B, using the mean and variance of each class.\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    PARAMETERS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    mu_a / mu_b: matrix with the mean for class A / B\n",
    "    \n",
    "    V_a / V_b: matrix with variance for class A / B\n",
    "    \"\"\"\n",
    "    delta_mu = mu_a - mu_b\n",
    "    W = V_a + V_b\n",
    "    W_inv = np.linalg.inv(W)\n",
    "    return W_inv @ delta_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_a = np.vstack([1, 2])\n",
    "mu_b = np.vstack([0, 1])\n",
    "V_a = np.array([[1, 2], [2, 2]])\n",
    "V_b = np.array([[1, 1], [1, 2]])\n",
    "\n",
    "fisher_disc(mu_a, mu_b, V_a, V_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36065574],\n",
       "       [-1.09016393],\n",
       "       [ 0.32786885]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_a = np.vstack([1, .7, .5])\n",
    "mu_b = np.vstack([.6, 1, .2])\n",
    "V_a = np.array([[.2, .1, 0], [.1, .1, 0], [0, 0, .2]])\n",
    "V_b = np.array([[.15, 0, .1], [0, .3, 0], [.1, 0, .3]])\n",
    "\n",
    "fisher_disc(mu_a, mu_b, V_a, V_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08764150246784272\n",
      "0.2699548325659403\n",
      "0.6475879783294588\n",
      "1.2098536225957173\n",
      "1.7603266338214976\n",
      "1.9947114020071635\n",
      "1.7603266338214971\n",
      "1.2098536225957166\n",
      "0.6475879783294587\n",
      "0.2699548325659403\n",
      "0.08764150246784272\n"
     ]
    }
   ],
   "source": [
    "ratio_vals = np.arange(0, 1.1, .1)\n",
    "for i in ratio_vals:\n",
    "    print(gaussian(i, .5, .2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_classifier_NEW(xs, ys=None, distributions_x=[gaussian, uniform],\n",
    "                        distributions_y=None, params_x=[[0, 1], [10]],\n",
    "                        params_y=None, categories=None):\n",
    "    \n",
    "    \"\"\"Creates a Bayesian classifier to categorise events in a dataset.\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    PARAMETERS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    xs: array-like. \n",
    "        the x data that we want to classify, or simply the data for a \n",
    "        one dimensional dataset.\n",
    "        \n",
    "    ys: array-like.\n",
    "        the y data for a 2d dataset.\n",
    "    \n",
    "    distributions_x: list.\n",
    "                   contains the functions that act as the distributions\n",
    "                   for each classifier model for the x data (or simply\n",
    "                   the data if ys=None).\n",
    "                   \n",
    "    distributions_y: list.\n",
    "                    contains the functions that act as the distributions\n",
    "                    for each classifier model for the y data.\n",
    "                   \n",
    "    params_x / params_y: list of lists.\n",
    "            containing the parameters for the distribution functions for\n",
    "            the x / y data\n",
    "            \n",
    "    categories: default=None.\n",
    "                otherwise should be a list containing the class names\n",
    "                as strings\n",
    "                \n",
    "    -+-+-+-+-+-\n",
    "    RETURNS\n",
    "    -+-+-+-+-+-\n",
    "    class_list: list containing:\n",
    "                - indices of the classified events corresponding to\n",
    "                the distribution in the distributions list\n",
    "                - names of the classified class if categories != None.\n",
    "    \"\"\"\n",
    "    \n",
    "    class_list = []\n",
    "    p_list = np.zeros((len(xs), len(distributions_x)))\n",
    "    if ys == None:\n",
    "        for row, x in enumerate(xs):\n",
    "            for i in range(len(distributions_x)):\n",
    "                p_list[row, i] = (distributions_x[i](x, *params_x[i]))\n",
    "\n",
    "    \n",
    "    else:\n",
    "        for row, (x, y) in enumerate(zip(xs, ys)):\n",
    "\n",
    "            for i in range(len(distributions_x)):\n",
    "                p_a_x = distributions_x[i](x, *params_x[i])\n",
    "                p_a_y = distributions_y[i](y, *params_y[i])\n",
    "                p_list[row, i] = (p_a_x*p_a_y)\n",
    "            \n",
    "    for data_point in p_list:    \n",
    "        classification = np.argmax(data_point)\n",
    "        if categories != None:\n",
    "            classification = categories[classification]\n",
    "        class_list.append(classification)\n",
    "        \n",
    "    return class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', ' B', ' B', ' B', 'A', 'A']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [-1, 0, 1, 3, 2, .5]\n",
    "y = [1, 2, 1, 3, -1, 1]\n",
    "classes = [\"A\", \" B\"]\n",
    "\n",
    "bayes_classifier_NEW(x, y, [gaussian, gaussian], [gaussian, gaussian], \n",
    "                   [[0, 1], [1, 1]], [[0, 1], [2, 1]], categories=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', ' B', ' B', ' B', 'A', 'A']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PyStats import bayes_classifier\n",
    "\n",
    "x = [-1, 0, 1, 3, 2, .5]\n",
    "y = [1, 2, 1, 3, -1, 1]\n",
    "classes = [\"A\", \" B\"]\n",
    "\n",
    "bayes_classifier(x, y, [gaussian, gaussian], [gaussian, gaussian], \n",
    "                   [[0, 1], [1, 1]], [[0, 1], [2, 1]], categories=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separation(mu_a, mu_b, sig_a, sig_b):\n",
    "    \"\"\"\n",
    "    Calculates the separation between two distributions of events.\n",
    "    \n",
    "    -+-+-+-+-+-\n",
    "    PARAMETERS\n",
    "    -+-+-+-+-+-\n",
    "    \n",
    "    mu_a / mu_b: mean of the distribution a / b\n",
    "    \n",
    "    sig_a / sig_b: error of distribution a / b\n",
    "    \"\"\"\n",
    "    \n",
    "    return (mu_a - mu_b)**2 / (sig_a**2 + sig_b**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
